{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'C://Users//dkvhe//OneDrive//Desktop//New-folder//mpc-1//BIE_files//BIE.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_html(r.content,attrs = {'id': 'curr_table'})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('C://Users//dkvhe//OneDrive//Desktop//New-folder//bipc-1//BIE_files//BIE.html', 'r') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "table = soup.find('table', class_='table')\n",
    "\n",
    "columns = []\n",
    "for row in table.find_all('tr'):\n",
    "    columns.append([cell.text for cell in row.find_all('td')])\n",
    "\n",
    "df = pd.DataFrame(columns, columns=['Column 1', 'Column 2', 'Column 3','Column 4', 'Column 5', 'Column 6','Column 7'])\n",
    "\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Student Name', 'AYYAGALLA SANTHI', 'BHAVANASI  CHENCHU VINDYA SREE', 'CHERUVUPALLI RAGHAVI', 'DARSI CHANDRIKA', 'DATLA PRAVALLIKA', 'GALI SAI MEGHANA', 'GUNDUGALLA NISHITHA', 'JADA HIMA BINDU', 'JALLI VENKATA JAHNAVI', 'JETTY SUJITHA', 'KASALA CHANDANA PRIYA', 'KASUVU SUKANYA', 'KURAKU SINDHU', 'LINGAM LAKSHMI PRASANNA', 'MADAPURU DIVYA HARSHINI', 'MADDELA DIVYA', 'NARU INDHU', 'PALEM AKHILA', 'PANDIKALA PUJITHA', 'PASALA VYSHNAVI', 'PENIDLIMARI SRIVANI', 'PUTTURU   SUJITHA', 'RAMAPURAM SRILAXMI', 'RAMAVATHI GANGOTHRI', 'REDDIPOGU AKHILA', 'TAPPETA VARSHITHA', 'THIPPANA DEEPIKA', 'VAKAMALLA SOWMYA', 'YARRAMASU SHARON ROJA']\n"
     ]
    }
   ],
   "source": [
    "file = 'C://Users//dkvhe//OneDrive//Desktop//New-folder//mpc-2//BIE_files//BIE.html'\n",
    "soup = BeautifulSoup(open(file), 'html.parser')\n",
    "\n",
    "# Extract the div tag with the class name \"my_class\"\n",
    "# div_tag = soup.find('div', class_='col-md-3')\n",
    "\n",
    "div_text=soup.find_all(\"div\",class_=\"col-md-3\")\n",
    "# soup.find_all(\"h3\",{\"class\":\"archive-list__title\"}).get_text()\n",
    "prices_text = [p.get_text() for p in div_text]\n",
    "print(prices_text)\n",
    "dict = {'stu': prices_text}\n",
    "df = pd.DataFrame(dict) \n",
    "    \n",
    "# write the DataFrame to a CSV file\n",
    "df.to_csv('Data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smartproxy Launches Dedicated ISP Proxies', 'GeoSurf Is Shutting Down on December 20', 'Smartproxy Makes Its Mobile Proxies Up to 53% Cheaper', 'How to Use cURL With Python for Web Scraping', 'How to Scrape Reddit with Python: an Easy Web Scraping Tutorial', 'The Best Python HTTP Clients (Python Requests Alternatives)', 'Web Scraping with Pythonâ€™s lxml : A Tutorial for Beginners', 'Scrapy vs Selenium: Which is Better for Web Scraping in 2024?', 'How to Create an eBay Stealth Account in 2024']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "r=requests.get(\"https://proxyway.com/\")\n",
    "soup=BeautifulSoup(r.content,\"html.parser\")\n",
    "div_text=soup.find_all(\"h3\",class_=\"archive-list__title\")\n",
    "# soup.find_all(\"h3\",{\"class\":\"archive-list__title\"}).get_text()\n",
    "prices_text = [p.get_text() for p in div_text]\n",
    "print(prices_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "# create three lists for employee name, id, and salary\n",
    "emp = [\"XYZ\", \"ABC\", \"PQR\", \"EFG\"] \n",
    "id = [11, 12, 51, 46] \n",
    "sly = [2000, 8000, 5000, 10000] \n",
    "     \n",
    "# create a dictionary with the three lists\n",
    "dict = {'Employee': emp, 'ID': id, 'Salary': sly}  \n",
    "       \n",
    "# create a Pandas DataFrame from the dictionary\n",
    "df = pd.DataFrame(dict) \n",
    "    \n",
    "# write the DataFrame to a CSV file\n",
    "df.to_csv('EmployeeData.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
